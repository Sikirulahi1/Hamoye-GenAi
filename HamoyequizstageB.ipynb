{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25_B83GZReYm",
        "outputId": "bf74f77a-b096-44bf-b317-ee3f662ce440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==v0.28.1\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m543.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==v0.28.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==v0.28.1) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==v0.28.1) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==v0.28.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==v0.28.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==v0.28.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==v0.28.1) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==v0.28.1) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==v0.28.1) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==v0.28.1) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==v0.28.1) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==v0.28.1) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==v0.28.1) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.28.1\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.36 (from langchain)\n",
            "  Downloading langchain_community-0.0.36-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.48 (from langchain)\n",
            "  Downloading langchain_core-0.1.48-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.52-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.48->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.5 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.17 langchain-community-0.0.36 langchain-core-0.1.48 langchain-text-splitters-0.0.1 langsmith-0.1.52 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.1 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# installing the necessary libraries\n",
        "!pip install openai==v0.28.1\n",
        "!pip install --upgrade python-dotenv\n",
        "!pip install --upgrade langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the libraries\n",
        "import openai\n",
        "import IPython\n",
        "import os\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "dX2bun70Sdik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_open_params(model, temperature, max_tokens, top_p, frequency_penalty, presence_penalty):\n",
        "    \"\"\"\n",
        "    Set parameters for OpenAI API.\n",
        "    \"\"\"\n",
        "    openai_params = {}\n",
        "    openai_params['model'] = model\n",
        "    openai_params['temperature'] = temperature\n",
        "    openai_params['max_tokens'] = max_tokens\n",
        "    openai_params['top_p'] = top_p\n",
        "    openai_params['frequency_penalty'] = frequency_penalty\n",
        "    openai_params['presence_penalty'] = presence_penalty\n",
        "    return openai_params\n",
        "\n",
        "def get_completion(params, prompt):\n",
        "    \"\"\"\n",
        "    Get completion from OpenAI API.\n",
        "    \"\"\"\n",
        "    response = openai.Completion.create(\n",
        "        engine=params['model'],\n",
        "        prompt=prompt,\n",
        "        temperature=params['temperature'],\n",
        "        max_tokens=params['max_tokens'],\n",
        "        top_p=params['top_p'],\n",
        "        frequency_penalty=params['frequency_penalty'],\n",
        "        presence_penalty=params['presence_penalty'],\n",
        "    )\n",
        "    return response"
      ],
      "metadata": {
        "id": "29BJNV2RS1_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-grxxz_uVge_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KIlCQr9nVpDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are a knowledgeable assistant. A user will ask a question and you should provide a clear and concise answer briefly enough to fit as an MCQ option.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What causes the Northern Lights?\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=150,\n",
        "    top_p=1\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "38-LL19hTiWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",  # Note: This model might be unavailable, consider alternatives\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Provide a concise fact about the event in history mentioned by the user briefly enough to fit as an MCQ option.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What was the main cause of the American Civil War?\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.7,  # Increased for some creativity in fact selection\n",
        "    max_tokens=30,  # Limited for a concise fact\n",
        "    top_p=0.9  # Balanced informativeness and diversity\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "SiLu9q7NT-HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are to summarize the provided text into a concise form, maintaining the key points and context, briefly enough to fit as an MCQ option.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"The economy has been growing steadily over the past few quarters, driven by increases in consumer spending and substantial investments in renewable energy infrastructure. Unemployment rates have also fallen to record lows as new industries are creating more jobs.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=100,\n",
        "    top_p=1\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "O-kkiASfUJVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Translate the following sentence into Spanish concisely to fit as an MCQ option.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What time is the meeting?\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=30,\n",
        "    top_p=1\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "g8yJg0KOUdKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Classify the sentiment of the text provided by the user as positive, negative, or neutral.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"I had an awful experience at the restaurant. The food was bland and the service was slow.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.7,  # Increased for some creativity\n",
        "    max_tokens=30,  # Increased to allow for a more complete response\n",
        "    top_p=0.9  # Adjusted for a balance between informativeness and diversity\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "Uej10MKpUsZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You will be provided with a sentence in English, and your task is to translate it into German.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"How do you say 'I love to travel' in German?\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=64,\n",
        "    top_p=1\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "-Z_UohxqUzsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"What is cloud computing?\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the concept of cloud computing briefly enough to fit as an MCQ option.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.7,  # Increased for some creativity\n",
        "    max_tokens=60,  # Increased to allow for a more comprehensive explanation\n",
        "    top_p=0.9  # Adjusted for a balance between informativeness and diversity\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "uS-2C69GVDcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        " messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Who is known as the father of computer science?\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Provide a brief, accurate answer to the user’s question that can be used as an MCQ option.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.7,\n",
        "    max_tokens=30,\n",
        "    top_p=0.9\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "LldVyfqVVMM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Summarize the text in a concise form, highlighting key points about the economy.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"The economy has been growing steadily over the past few quarters, driven by increases in consumer spending and substantial investments in renewable energy infrastructure. Unemployment rates have also fallen to record lows as new industries are creating more jobs.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0.7,  # Increased for some creativity in phrasing\n",
        "    max_tokens=30,  # Reduced for a tighter MCQ option\n",
        "    top_p=0.9  # Balanced informativeness and diversity\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "rcPC8ktQVTRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Classify the following text's tone in a brief form that could fit as an MCQ option.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"The meeting was cancelled due to unforeseen circumstances.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=15,\n",
        "    top_p=1\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "pVRvox3rV3kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Summarize the following text into a concise phrase suitable for an MCQ answer option.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"The internet was developed to help researchers communicate and share computing resources. Today, it connects millions of people and devices across the globe.\"\n",
        "        }\n",
        "    ],\n",
        "    temperature=0,\n",
        "    max_tokens=30,\n",
        "    top_p=1\n",
        ")\n",
        "\n",
        "print(response.choices[0].message['content'])"
      ],
      "metadata": {
        "id": "AqGeTZTAVrZr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}